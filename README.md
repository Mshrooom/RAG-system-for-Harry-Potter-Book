A fully functional Retrieval-Augmented Generation (RAG) system that integrates LangChain, LangGraph, FAISS, and RAGAS evaluation with Hugging Face embeddings and GPT-4o (via OpenRouter). 
This project demonstrates how to build a production-ready pipeline for document ingestion, semantic search, retrieval, and response generation, along with evaluation metrics to measure accuracy and reliability.

---

##  Architecture Overview

```mermaid
flowchart LR
    A[Upload Docs] --> B[Hugging Face Embeddings]
    B --> C[FAISS Vector Store]
    C --> D[Retriever - LangChain]
    D --> E[LangGraph Workflow]
    E --> F[GPT-4o via OpenRouter]
    F --> G[Final Answer]
    G --> H[RAGAS Evaluation]


```
--------------------
##  Key Components

* **LangChain** ‚Äì Builds the RAG pipeline (retrieval + generation).
* **LangGraph** ‚Äì Adds structured workflows for better orchestration.
* **FAISS** ‚Äì Vector database for efficient similarity search.
* **Hugging Face Embeddings** ‚Äì Converts docs into vectors.
* **OpenRouter (GPT-4o)** ‚Äì Free access to GPT-4o for LLM answers.
* **RAGAS** ‚Äì Evaluates retrieval accuracy & faithfulness.

---

##  Quickstart

### 1Ô∏è Clone the Repository

```bash
git clone https://github.com/Mshroom/RAG-system-for-Harry-Potter-Book.git
cd complex-RAG-guide
```

### 2Ô∏è Create Virtual Environment & Install Dependencies

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt
```

### 3Ô∏è Add API Keys

Create a `.env` file in the root directory:

```
OPENROUTER_API_KEY=your_api_key_here
```

üëâ Get your free API key from [OpenRouter](https://openrouter.ai).

---

##  Beginner Tutorial

Here‚Äôs a minimal example to **embed documents, store them in FAISS, and query GPT-4o**.

```python
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
import os

# Load API key
os.environ["OPENAI_API_KEY"] = os.getenv("OPENROUTER_API_KEY")

# Step 1: Define documents
docs = [
    "Harry Potter is a wizard who studied at Hogwarts.",
    "Hogwarts is a school of magic in Scotland."
]

# Step 2: Create embeddings
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# Step 3: Store embeddings in FAISS
db = FAISS.from_texts(docs, embedding_model)

# Step 4: Initialize GPT-4o via OpenRouter
llm = ChatOpenAI(model="openai/gpt-4o", openai_api_base="https://openrouter.ai/api/v1")

# Step 5: Build Retrieval-QA chain
qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=db.as_retriever()
)

# Step 6: Ask a question
query = "Who is Harry Potter?"
answer = qa.run(query)

print("Q:", query)
print("A:", answer)


##  Evaluating with RAGAS

Once you‚Äôve tested your pipeline, evaluate it with RAGAS:

```python
from ragas.metrics import faithfulness, answer_relevance, context_recall
from ragas import evaluate

# Example QA pairs for evaluation
examples = [
    {"question": "Who is Harry Potter?",
     "answer": "Harry Potter is a wizard who studied at Hogwarts.",
     "contexts": ["Harry Potter is a wizard who studied at Hogwarts."]}
]

# Run evaluation
result = evaluate(examples, metrics=[faithfulness, answer_relevance, context_recall])
print(result)
```

---

## üìÇ Project Structure

```
complex-RAG-guide/
‚îÇ‚îÄ‚îÄ main.py              # Main RAG pipeline
‚îÇ‚îÄ‚îÄ helper_functions.py       # RAGAS evaluation script
‚îÇ‚îÄ‚îÄ requirements.txt    # Dependencies
‚îÇ‚îÄ‚îÄ .env.example        # Example API key setup
‚îÇ‚îÄ‚îÄ data/               # Folder for input documents
‚îÇ‚îÄ‚îÄ vectorstore/        # Stored FAISS index
```



##  Resources

* [LangChain Docs](https://python.langchain.com)
* [LangGraph](https://www.langchain.com/langgraph)
* [FAISS](https://faiss.ai)
* [RAGAS](https://docs.ragas.io)
* [OpenRouter](https://openrouter.ai)

---

‚ö° With this repo, you‚Äôll build, query, and evaluate a complete **end-to-end RAG system** in just a few steps.
